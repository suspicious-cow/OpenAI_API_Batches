{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Batches\n",
    "\n",
    "The Batch API endpoint allows users to submit requests for asynchronous batch processing. We will process these requests within 24 hours. The details of each request will be read from a pre-uploaded file, and the responses will be written to an output file. You can query the batch object for status updates and results. Each model will be offered at 50% cost discount vs. the synchronous APIs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univeral Code Used for the Entire Notebook\n",
    "\n",
    "Let's set up our libraries and client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client we can use\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Batch File\n",
    "\n",
    "Batches start with a .jsonl file where each line contains the details of an individual request to the API. For now, the available endpoints are /v1/chat/completions (Chat Completions API) and /v1/embeddings (Embeddings API). For a given input file, the parameters in each line's body field are the same as the parameters for the underlying endpoint. Each request must include a unique custom_id value, which you can use to reference results after completion. Here's an example of an input file with 2 requests. Note that each input file can only include requests to a single model.\n",
    "\n",
    "NOTE: For some insane reason you are required to indicate the API endpoint here and in the batch creation later on. Presumably, OpenAI will one day allow hitting multiple different APIs in one batch request; but today is not that day. \n",
    "\n",
    "<br/>\n",
    "Examples:\n",
    "\n",
    "```\n",
    "{\"custom_id\": \"request-1\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Give me three paragraphs on the penguin lifecycle.\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "{\"custom_id\": \"request-2\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Give me three paragraphs on penguin mating habits.\"}],\"max_tokens\": 1000}}\n",
    "\n",
    "{\"custom_id\": \"request-3\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Give me three paragraphs on penguin species differences.\"}],\"max_tokens\": 1000}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the File\n",
    "\n",
    "After creating your batch file, you must upload it so that you can reference it correctly when kicking off batches. Upload your .jsonl file using the Files API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bad_batch_input_file = client.files.create(\n",
    "    file=open(\"./artifacts/badbatchinput.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "good_batch_input_file = client.files.create(\n",
    "    file=open(\"./artifacts/goodbatchinput.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Batch\n",
    "\n",
    "Once you've successfully uploaded your input file, you can use the input File object's ID to create a batch. For now, the completion window can only be set to 24h. You can also provide custom metadata via an optional metadata parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_68MMFa1Z4Fq934ja1sU9UtF7', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-SEmMGmpsknbexiwfiFtYvSiF', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407608, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'bad nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "\n",
      "\n",
      "\n",
      "Batch(id='batch_E9enNhllf055ZCFio5B0Tvjd', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407608, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "bad_batch_input_file_id = bad_batch_input_file.id\n",
    "\n",
    "bad_batch = client.batches.create(\n",
    "    input_file_id=bad_batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"bad nightly penguin job\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(bad_batch)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "good_batch_input_file_id = good_batch_input_file.id\n",
    "\n",
    "good_batch = client.batches.create(\n",
    "    input_file_id=good_batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"good nightly penguin job\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(good_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Batch Status\n",
    "\n",
    "The status of a given Batch object can be any of the following:\n",
    "\n",
    "| STATUS      | DESCRIPTION                                                                  |\n",
    "|-------------|------------------------------------------------------------------------------|\n",
    "| validating  | the input file is being validated before the batch can begin                 |\n",
    "| failed      | the input file has failed the validation process                             |\n",
    "| in_progress | the input file was successfully validated and the batch is currently being run |\n",
    "| finalizing  | the batch has completed and the results are being prepared                   |\n",
    "| completed   | the batch has been completed and the results are ready                       |\n",
    "| expired     | the batch was not able to be completed within the 24-hour time window        |\n",
    "| cancelling  | the batch is being cancelled (may take up to 10 minutes)                     |\n",
    "| cancelled   | the batch was cancelled                                                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_68MMFa1Z4Fq934ja1sU9UtF7', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-SEmMGmpsknbexiwfiFtYvSiF', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='duplicate_custom_id', line=2, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=3, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id')], object='list'), expired_at=None, expires_at=1720407608, failed_at=1720321208, finalizing_at=None, in_progress_at=None, metadata={'description': 'bad nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "\n",
      "\n",
      "\n",
      "Batch(id='batch_E9enNhllf055ZCFio5B0Tvjd', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407608, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(client.batches.retrieve(bad_batch.id))\n",
    "print(\"\\n\\n\")\n",
    "print(client.batches.retrieve(good_batch.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing the Batches\n",
    "\n",
    "At any time, you can see all your batches. For users with many batches, you can use the limit and after parameters to paginate your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Batch](data=[Batch(id='batch_E9enNhllf055ZCFio5B0Tvjd', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407608, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_68MMFa1Z4Fq934ja1sU9UtF7', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-SEmMGmpsknbexiwfiFtYvSiF', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='duplicate_custom_id', line=2, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=3, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id')], object='list'), expired_at=None, expires_at=1720407608, failed_at=1720321208, finalizing_at=None, in_progress_at=None, metadata={'description': 'bad nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_b4bNt66SAVJaOlvs3Iw1lJ8g', completion_window='24h', created_at=1720320112, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='cancelled', cancelled_at=1720320121, cancelling_at=1720320117, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720406512, failed_at=None, finalizing_at=None, in_progress_at=1720320113, metadata={'description': 'good nightly penguin job'}, output_file_id='file-0ulWfvAjh7NrX2FbZwb5O9la', request_counts=BatchRequestCounts(completed=3, failed=0, total=3)), Batch(id='batch_EU9lESgy0j3nWHqBaiuiD43m', completion_window='24h', created_at=1720320048, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1720320057, error_file_id=None, errors=None, expired_at=None, expires_at=1720406448, failed_at=None, finalizing_at=1720320056, in_progress_at=1720320049, metadata={'description': 'good nightly penguin job'}, output_file_id='file-IqcypXONtZ5ULSfFHLSxeVUK', request_counts=BatchRequestCounts(completed=3, failed=0, total=3)), Batch(id='batch_2ayJiMlXB1KuLEnnsirj85eP', completion_window='24h', created_at=1720319934, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='cancelled', cancelled_at=1720320540, cancelling_at=1720319934, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720406334, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))], object='list', first_id='batch_E9enNhllf055ZCFio5B0Tvjd', last_id='batch_2ayJiMlXB1KuLEnnsirj85eP', has_more=True)\n",
      "\n",
      "We have 20 batches\n",
      "\n",
      "batch_E9enNhllf055ZCFio5B0Tvjd\n",
      "validating\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_68MMFa1Z4Fq934ja1sU9UtF7\n",
      "failed\n",
      "bad nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_b4bNt66SAVJaOlvs3Iw1lJ8g\n",
      "cancelled\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_EU9lESgy0j3nWHqBaiuiD43m\n",
      "completed\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_2ayJiMlXB1KuLEnnsirj85eP\n",
      "cancelled\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_FtQXjIiZ1TQWtAEgPoYnXqwN\n",
      "completed\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_aeo2ZMmdavhEdeebQ5dNdCaz\n",
      "failed\n",
      "bad nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_digFaDnZiTa0WoPmjcwjgXwt\n",
      "completed\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_EIXIzJGPItJWrZM8eX089EQI\n",
      "failed\n",
      "bad nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_SFkOFAfJejNfQCfpK611h7UI\n",
      "completed\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_Pe9jWAK6zGIVxNSyIUMsoe5n\n",
      "failed\n",
      "bad nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_7gHdkZDI5stgn8amRIxDek6E\n",
      "completed\n",
      "good nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_uiGGOF2Ezj2ghrbyIVxkGOXZ\n",
      "failed\n",
      "bad nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_yVmw1bKlyyTYE9GmkxRjJLBx\n",
      "completed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_iiTGl4vSFF6xL1AkGhVjOvrl\n",
      "failed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_2JxALjwCcAIoMYKBZWkkfoLs\n",
      "failed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_WS7lPOyIBe0ukFMkpmx8hbP4\n",
      "failed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_YaSbx4ToxpIZXIQg7FKTapyC\n",
      "failed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_A05MUZX2CRhuJqBywXS10gkP\n",
      "failed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "batch_hcz7fuAGsbqu31o0p6BtjfZU\n",
      "failed\n",
      "nightly penguin job\n",
      "\n",
      "\n",
      "\n",
      "SyncCursorPage[Batch](data=[Batch(id='batch_E9enNhllf055ZCFio5B0Tvjd', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407608, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_68MMFa1Z4Fq934ja1sU9UtF7', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-SEmMGmpsknbexiwfiFtYvSiF', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='duplicate_custom_id', line=2, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=3, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id')], object='list'), expired_at=None, expires_at=1720407608, failed_at=1720321208, finalizing_at=None, in_progress_at=None, metadata={'description': 'bad nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_b4bNt66SAVJaOlvs3Iw1lJ8g', completion_window='24h', created_at=1720320112, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='cancelled', cancelled_at=1720320121, cancelling_at=1720320117, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720406512, failed_at=None, finalizing_at=None, in_progress_at=1720320113, metadata={'description': 'good nightly penguin job'}, output_file_id='file-0ulWfvAjh7NrX2FbZwb5O9la', request_counts=BatchRequestCounts(completed=3, failed=0, total=3)), Batch(id='batch_EU9lESgy0j3nWHqBaiuiD43m', completion_window='24h', created_at=1720320048, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1720320057, error_file_id=None, errors=None, expired_at=None, expires_at=1720406448, failed_at=None, finalizing_at=1720320056, in_progress_at=1720320049, metadata={'description': 'good nightly penguin job'}, output_file_id='file-IqcypXONtZ5ULSfFHLSxeVUK', request_counts=BatchRequestCounts(completed=3, failed=0, total=3)), Batch(id='batch_2ayJiMlXB1KuLEnnsirj85eP', completion_window='24h', created_at=1720319934, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='cancelled', cancelled_at=1720320540, cancelling_at=1720319934, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720406334, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))], object='list', first_id='batch_E9enNhllf055ZCFio5B0Tvjd', last_id='batch_2ayJiMlXB1KuLEnnsirj85eP', has_more=True)\n",
      "SyncCursorPage[Batch](data=[Batch(id='batch_E9enNhllf055ZCFio5B0Tvjd', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407608, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_68MMFa1Z4Fq934ja1sU9UtF7', completion_window='24h', created_at=1720321208, endpoint='/v1/chat/completions', input_file_id='file-SEmMGmpsknbexiwfiFtYvSiF', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='duplicate_custom_id', line=2, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id'), BatchError(code='duplicate_custom_id', line=3, message='The custom_id for this request is a duplicate of another request. The custom_id parameter must be unique for each request in a batch.', param='custom_id')], object='list'), expired_at=None, expires_at=1720407608, failed_at=1720321208, finalizing_at=None, in_progress_at=None, metadata={'description': 'bad nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_b4bNt66SAVJaOlvs3Iw1lJ8g', completion_window='24h', created_at=1720320112, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='cancelled', cancelled_at=1720320121, cancelling_at=1720320117, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720406512, failed_at=None, finalizing_at=None, in_progress_at=1720320113, metadata={'description': 'good nightly penguin job'}, output_file_id='file-0ulWfvAjh7NrX2FbZwb5O9la', request_counts=BatchRequestCounts(completed=3, failed=0, total=3)), Batch(id='batch_EU9lESgy0j3nWHqBaiuiD43m', completion_window='24h', created_at=1720320048, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1720320057, error_file_id=None, errors=None, expired_at=None, expires_at=1720406448, failed_at=None, finalizing_at=1720320056, in_progress_at=1720320049, metadata={'description': 'good nightly penguin job'}, output_file_id='file-IqcypXONtZ5ULSfFHLSxeVUK', request_counts=BatchRequestCounts(completed=3, failed=0, total=3)), Batch(id='batch_2ayJiMlXB1KuLEnnsirj85eP', completion_window='24h', created_at=1720319934, endpoint='/v1/chat/completions', input_file_id='file-JwfDUxjAcYGRB7bYl2N8uCz8', object='batch', status='cancelled', cancelled_at=1720320540, cancelling_at=1720319934, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720406334, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))], object='list', first_id='batch_E9enNhllf055ZCFio5B0Tvjd', last_id='batch_2ayJiMlXB1KuLEnnsirj85eP', has_more=True)\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 batches\n",
    "print(client.batches.list(limit=5))\n",
    "\n",
    "# Convert the returned object to a list to get the length\n",
    "batches = list(client.batches.list())\n",
    "print(\"\\nWe have \" + str(len(batches)) + \" batches\\n\")\n",
    "\n",
    "# Iterate over the batches and print their ids, statuses, and descriptions\n",
    "for batch in batches:\n",
    "    print(batch.id)\n",
    "    print(batch.status)\n",
    "    print(batch.metadata.get(\"description\"))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "# Use a dictionary for extra_query parameter\n",
    "print(client.batches.list(limit=5, extra_query={\"metadata.description\": \"good\"}))\n",
    "print(client.batches.list(limit=5, extra_query={\"metadata.description\": \"good\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancelling a Batch\n",
    "\n",
    "If necessary, you can cancel an ongoing batch. The batch's status will change to cancelling until in-flight requests are complete (up to 10 minutes), after which the status will change to cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_LC0NkXotFC9veV5NRyIlkOjc', completion_window='24h', created_at=1720321209, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407609, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n",
      "\n",
      "\n",
      "\n",
      "Batch(id='batch_LC0NkXotFC9veV5NRyIlkOjc', completion_window='24h', created_at=1720321209, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407609, failed_at=None, finalizing_at=None, in_progress_at=1720321210, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=3))\n",
      "\n",
      "\n",
      "\n",
      "Batch(id='batch_LC0NkXotFC9veV5NRyIlkOjc', completion_window='24h', created_at=1720321209, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1720321215, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407609, failed_at=None, finalizing_at=None, in_progress_at=1720321210, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=3))\n",
      "\n",
      "\n",
      "\n",
      "Batch(id='batch_LC0NkXotFC9veV5NRyIlkOjc', completion_window='24h', created_at=1720321209, endpoint='/v1/chat/completions', input_file_id='file-9pZGMM3GbUgHTFrFhVAw6dVI', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1720321215, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1720407609, failed_at=None, finalizing_at=None, in_progress_at=1720321210, metadata={'description': 'good nightly penguin job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=3, failed=0, total=3))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "good_batch_input_file_id = good_batch_input_file.id\n",
    "\n",
    "dead_batch_walking = client.batches.create(\n",
    "    input_file_id=good_batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"good nightly penguin job\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(dead_batch_walking)\n",
    "time.sleep(5)\n",
    "print(\"\\n\\n\")\n",
    "print(client.batches.retrieve(dead_batch_walking.id))\n",
    "print(\"\\n\\n\")\n",
    "print(client.batches.cancel(dead_batch_walking.id))\n",
    "time.sleep(5)\n",
    "print(\"\\n\\n\")\n",
    "print(client.batches.retrieve(dead_batch_walking.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Results\n",
    "\n",
    "Once the batch is complete, you can download the output by making a request against the Files API via the output_file_id field from the Batch object and writing it to a file on your machine, in this case batch_output.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch the content of the file\n",
    "content = client.files.content(client.batches.retrieve(good_batch.id).output_file_id)\n",
    "\n",
    "content.write_to_file(\"./artifacts/goodbatchoutput.jsonl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NormalProgramming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
